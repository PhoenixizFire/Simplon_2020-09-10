{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de critiques de cinéma\n",
    "Est ce que le champ lexical (pondéré) d'une critique permet de déterminer si elle est positive ou négative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:09:42.237663Z",
     "start_time": "2020-09-10T12:09:39.220854Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:09:42.301359Z",
     "start_time": "2020-09-10T12:09:42.238661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:09:42.502053Z",
     "start_time": "2020-09-10T12:09:42.302334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kingd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from imdb_utils import preprocess, tokenize, extract_vocabulary, create_bow, create_word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Large Movie Review Dataset\n",
    "\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fichier préparé: `Data/imdb/imdb_dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:01:06.654874Z",
     "start_time": "2020-09-10T15:01:06.193904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "data_path = '../'\n",
    "\n",
    "imdb_data = pd.read_csv(os.path.join(data_path, 'IMDB dataset.csv'))\n",
    "\n",
    "print(imdb_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equilibre des classes dans `imdb_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation de la colonne `sentiment`en valeurs catégorielles (pour passer au numérique si besoin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données pour le développement\n",
    "Dataset (beaucoup) plus petit pour les phases de développement, à commenter lors de l'éxécution finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:01:08.628687Z",
     "start_time": "2020-09-10T15:01:08.565831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Some people seem to think this was the worst m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This is one of my favourite films, dating back...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A rousing adventure form director George Steve...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This film is an eery, but interesting film. I ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Lonesome Jim is kind of like a romantic dark c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Some people seem to think this was the worst m...  negative\n",
       "1  This is one of my favourite films, dating back...  positive\n",
       "2  A rousing adventure form director George Steve...  positive\n",
       "3  This film is an eery, but interesting film. I ...  positive\n",
       "4  Lonesome Jim is kind of like a romantic dark c...  negative"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = imdb_data.sample(frac=0.01, replace=False, random_state=9)\n",
    "imdb_data.reset_index(drop=True, inplace=True)\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation du dataset en `train` et `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T12:09:52.254594Z",
     "start_time": "2020-09-10T12:09:52.200623Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:19:10.614271Z",
     "start_time": "2020-09-10T15:19:10.561412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((350,), (150,), (350,), (150,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(imdb_data.review,imdb_data.sentiment,test_size=.3,random_state=9)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:07:35.384860Z",
     "start_time": "2020-09-10T15:07:35.333996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some people seem to think this was the worst movie they have ever seen, and I understand where they\\'re coming from, but I really have seen worse.<br /><br />That being said, the movies that I can recall (ie the ones I haven\\'t blocked out) that were worse than this, were so bad that they physically pained every sense that was involved with watching the movie. The movies that are worse than War Games 2 are the ones that make you want to gouge out your eyes, or stab sharp objects in your ears to keep yourself from having another piece of your soul ripped away from you by the awfulness.<br /><br />War Games: The Dead Code isn\\'t that bad, but it comes pretty close. Yes I was a fan of the original, but no I wasn\\'t expecting miracles from this one. Let\\'s face it the original wasn\\'t really that great of a movie in the first place, it was basically just a campy 80s teen romance flick with some geek-appeal to it.<br /><br />That\\'s all I was hoping for, something bad, but that might have tugged at my geek-strings. Was that too much to ask for? Is it really not possible to do better than the original War Games, even for a straight to video release? Well apparently that was too much to ask for. Stay away from this movie. At first it\\'s just bad, like \"Oh yeah, this is bad, but I\\'m kind of enjoying it, maybe the end will be good like in the original.\" And then it just gets worse and worse, and by the end, trust me, you will wish you had not seen this movie.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "Préparation du texte pour la segmentation  \n",
    "Actions que l'on effectuera sur l'ensemble du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:19:12.412349Z",
     "start_time": "2020-09-10T15:19:12.230681Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "#nltk.download()\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "X_train = X_train.map(lambda x: \" \".join(sent_detector.tokenize(x.strip().replace(\"<br />\",\" \"))))\n",
    "X_test = X_test.map(lambda x: \" \".join(sent_detector.tokenize(x.strip().replace(\"<br />\",\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:14:54.853711Z",
     "start_time": "2020-09-10T15:14:54.798880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>This is a good movie, although people unfamili...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>This film could of been a hell of a lot better...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>That's a weird, weird movie and doesn't deserv...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>I have been getting into the Hitchcock series ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>This was truly a heart warming movie. It is fi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>I saw this film without knowing much about it ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>... but watch Mary McDonnell's performance clo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>The creator of Donnie Darko brings you a twili...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>I remember this film fondly from seeing it in ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>The best thing about the movie is the name, as...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "25   This is a good movie, although people unfamili...  positive\n",
       "175  This film could of been a hell of a lot better...  negative\n",
       "62   That's a weird, weird movie and doesn't deserv...  negative\n",
       "6    I have been getting into the Hitchcock series ...  positive\n",
       "54   This was truly a heart warming movie. It is fi...  positive\n",
       "..                                                 ...       ...\n",
       "56   I saw this film without knowing much about it ...  negative\n",
       "438  ... but watch Mary McDonnell's performance clo...  positive\n",
       "126  The creator of Donnie Darko brings you a twili...  positive\n",
       "348  I remember this film fondly from seeing it in ...  positive\n",
       "382  The best thing about the movie is the name, as...  negative\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(X_train),pd.DataFrame(y_train)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:14:57.681883Z",
     "start_time": "2020-09-10T15:14:57.635018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some people seem to think this was the worst movie they have ever seen, and I understand where they\\'re coming from, but I really have seen worse. That being said, the movies that I can recall (ie the ones I haven\\'t blocked out) that were worse than this, were so bad that they physically pained every sense that was involved with watching the movie. The movies that are worse than War Games 2 are the ones that make you want to gouge out your eyes, or stab sharp objects in your ears to keep yourself from having another piece of your soul ripped away from you by the awfulness. War Games: The Dead Code isn\\'t that bad, but it comes pretty close. Yes I was a fan of the original, but no I wasn\\'t expecting miracles from this one. Let\\'s face it the original wasn\\'t really that great of a movie in the first place, it was basically just a campy 80s teen romance flick with some geek-appeal to it. That\\'s all I was hoping for, something bad, but that might have tugged at my geek-strings. Was that too much to ask for? Is it really not possible to do better than the original War Games, even for a straight to video release? Well apparently that was too much to ask for. Stay away from this movie. At first it\\'s just bad, like \"Oh yeah, this is bad, but I\\'m kind of enjoying it, maybe the end will be good like in the original.\" And then it just gets worse and worse, and by the end, trust me, you will wish you had not seen this movie.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retire les mots trop fréquents en anglais: `stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:19:15.578172Z",
     "start_time": "2020-09-10T15:19:15.221102Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "X_train = X_train.map(lambda x: word_tokenize(re.sub(\"[`,!?:.\\(\\)]\",\" \",x)))\n",
    "X_test = X_test.map(lambda x: word_tokenize(re.sub(\"[`,!?:.\\(\\)]\",\" \",x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:19:18.420886Z",
     "start_time": "2020-09-10T15:19:18.367002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some',\n",
       " 'people',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'think',\n",
       " 'this',\n",
       " 'was',\n",
       " 'the',\n",
       " 'worst',\n",
       " 'movie',\n",
       " 'they',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'seen',\n",
       " 'and',\n",
       " 'I',\n",
       " 'understand',\n",
       " 'where',\n",
       " 'they',\n",
       " \"'re\",\n",
       " 'coming',\n",
       " 'from',\n",
       " 'but',\n",
       " 'I',\n",
       " 'really',\n",
       " 'have',\n",
       " 'seen',\n",
       " 'worse',\n",
       " 'That',\n",
       " 'being',\n",
       " 'said',\n",
       " 'the',\n",
       " 'movies',\n",
       " 'that',\n",
       " 'I',\n",
       " 'can',\n",
       " 'recall',\n",
       " 'ie',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'I',\n",
       " 'have',\n",
       " \"n't\",\n",
       " 'blocked',\n",
       " 'out',\n",
       " 'that',\n",
       " 'were',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'this',\n",
       " 'were',\n",
       " 'so',\n",
       " 'bad',\n",
       " 'that',\n",
       " 'they',\n",
       " 'physically',\n",
       " 'pained',\n",
       " 'every',\n",
       " 'sense',\n",
       " 'that',\n",
       " 'was',\n",
       " 'involved',\n",
       " 'with',\n",
       " 'watching',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'The',\n",
       " 'movies',\n",
       " 'that',\n",
       " 'are',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'War',\n",
       " 'Games',\n",
       " '2',\n",
       " 'are',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'that',\n",
       " 'make',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'gouge',\n",
       " 'out',\n",
       " 'your',\n",
       " 'eyes',\n",
       " 'or',\n",
       " 'stab',\n",
       " 'sharp',\n",
       " 'objects',\n",
       " 'in',\n",
       " 'your',\n",
       " 'ears',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'yourself',\n",
       " 'from',\n",
       " 'having',\n",
       " 'another',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'your',\n",
       " 'soul',\n",
       " 'ripped',\n",
       " 'away',\n",
       " 'from',\n",
       " 'you',\n",
       " 'by',\n",
       " 'the',\n",
       " 'awfulness',\n",
       " 'War',\n",
       " 'Games',\n",
       " 'The',\n",
       " 'Dead',\n",
       " 'Code',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'that',\n",
       " 'bad',\n",
       " 'but',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'pretty',\n",
       " 'close',\n",
       " 'Yes',\n",
       " 'I',\n",
       " 'was',\n",
       " 'a',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'original',\n",
       " 'but',\n",
       " 'no',\n",
       " 'I',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'expecting',\n",
       " 'miracles',\n",
       " 'from',\n",
       " 'this',\n",
       " 'one',\n",
       " 'Let',\n",
       " \"'s\",\n",
       " 'face',\n",
       " 'it',\n",
       " 'the',\n",
       " 'original',\n",
       " 'was',\n",
       " \"n't\",\n",
       " 'really',\n",
       " 'that',\n",
       " 'great',\n",
       " 'of',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'place',\n",
       " 'it',\n",
       " 'was',\n",
       " 'basically',\n",
       " 'just',\n",
       " 'a',\n",
       " 'campy',\n",
       " '80s',\n",
       " 'teen',\n",
       " 'romance',\n",
       " 'flick',\n",
       " 'with',\n",
       " 'some',\n",
       " 'geek-appeal',\n",
       " 'to',\n",
       " 'it',\n",
       " 'That',\n",
       " \"'s\",\n",
       " 'all',\n",
       " 'I',\n",
       " 'was',\n",
       " 'hoping',\n",
       " 'for',\n",
       " 'something',\n",
       " 'bad',\n",
       " 'but',\n",
       " 'that',\n",
       " 'might',\n",
       " 'have',\n",
       " 'tugged',\n",
       " 'at',\n",
       " 'my',\n",
       " 'geek-strings',\n",
       " 'Was',\n",
       " 'that',\n",
       " 'too',\n",
       " 'much',\n",
       " 'to',\n",
       " 'ask',\n",
       " 'for',\n",
       " 'Is',\n",
       " 'it',\n",
       " 'really',\n",
       " 'not',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'do',\n",
       " 'better',\n",
       " 'than',\n",
       " 'the',\n",
       " 'original',\n",
       " 'War',\n",
       " 'Games',\n",
       " 'even',\n",
       " 'for',\n",
       " 'a',\n",
       " 'straight',\n",
       " 'to',\n",
       " 'video',\n",
       " 'release',\n",
       " 'Well',\n",
       " 'apparently',\n",
       " 'that',\n",
       " 'was',\n",
       " 'too',\n",
       " 'much',\n",
       " 'to',\n",
       " 'ask',\n",
       " 'for',\n",
       " 'Stay',\n",
       " 'away',\n",
       " 'from',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'At',\n",
       " 'first',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'just',\n",
       " 'bad',\n",
       " 'like',\n",
       " '``',\n",
       " 'Oh',\n",
       " 'yeah',\n",
       " 'this',\n",
       " 'is',\n",
       " 'bad',\n",
       " 'but',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'kind',\n",
       " 'of',\n",
       " 'enjoying',\n",
       " 'it',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'end',\n",
       " 'will',\n",
       " 'be',\n",
       " 'good',\n",
       " 'like',\n",
       " 'in',\n",
       " 'the',\n",
       " 'original',\n",
       " '``',\n",
       " 'And',\n",
       " 'then',\n",
       " 'it',\n",
       " 'just',\n",
       " 'gets',\n",
       " 'worse',\n",
       " 'and',\n",
       " 'worse',\n",
       " 'and',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'trust',\n",
       " 'me',\n",
       " 'you',\n",
       " 'will',\n",
       " 'wish',\n",
       " 'you',\n",
       " 'had',\n",
       " 'not',\n",
       " 'seen',\n",
       " 'this',\n",
       " 'movie']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T15:30:18.893970Z",
     "start_time": "2020-09-10T15:24:56.698907Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "X_train = X_train.map(lambda x: [i for i in x if not i in stopwords.words()])\n",
    "X_test = X_test.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Racinisation  \n",
    "SnowballStemmer: https://www.nltk.org/howto/stem.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T14:28:49.290797Z",
     "start_time": "2020-09-10T14:28:49.236817Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemport = SnowballStemmer(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation en sac de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la liste des critiques segmentées  \n",
    "L'indice dans la liste correspond à l'index du document dans le dataframe `train`  \n",
    "Assez long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple : reviews[0]  \n",
    "`['lack', 'content', 'movi', 'amaz', 'first', 'though', 'peopl', 'go', 'compar', 'rock', 'realli', 'surpris', 'say', 'worst', 'rock', 'stori', 'horribl', 'cast', 'ajay', 'devgan', 'jam', 'salman', 'khan', 'asin', 'got', 'ta', 'kid', 'music', 'okay', 'khanabadosh', 'track', 'movi', 'rest', 'bad', 'vipul', 'shah', 'still', 'learn', 'singh', 'king', 'critic', 'bash', 'comedi', 'asin', 'come', 'sorri', 'asin', 'fan', 'suck', 'big', 'time', 'movi', 'serious', 'bad', 'act', 'look', 'good', 'overdos', 'make', 'final', 'verdict', 'go', 'watch', 'aladin', 'famili', 'instead', 'wast', 'time']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulaire de notre corpus d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64574"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naïve Bayes\n",
    "Utilisation de scikit learn: [sklearn.naive_bayes.MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)  \n",
    "Paramètres en entrée de la fonction de scikit learn:\n",
    "- X : {array-like, sparse matrix} of shape (n_samples, n_features) : Training vectors, where n_samples is the number of samples and n_features is the number of features.\n",
    "- y : array-like of shape (n_samples,): Target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation de nos données d'entraînement à scikit learn `X`, `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque ligne de `X` correspond à un point dans l'espace défini par le vocabulaire. Les coordonnées sont nulles sauf pour les mots du sac de mot du document où elles sont égales au nombre d'occurence dans le document. Par exemple si on a les deux documents suivants:\n",
    "- `d1` \"le petit chat\"\n",
    "- `d2` \"le gros chien-chien\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chat', 'chien', 'gros', 'le', 'petit']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Après segmentation\n",
    "d1 = ['le', 'petit', 'chat']\n",
    "d2 = ['le', 'gros', 'chien', 'chien']\n",
    "documents = [d1, d2]\n",
    "\n",
    "# Vocabulaire du corpus\n",
    "V = list(sorted(extract_vocabulary(documents))) # Transformation du set en liste ordonnée pour pouvoir avoir accès aux indices\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'le': 1, 'petit': 1, 'chat': 1}),\n",
       " Counter({'le': 1, 'gros': 1, 'chien': 2})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation de la liste de documents en liste de sacs de mots\n",
    "documents = [create_bow(document) for document in documents]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>chien</th>\n",
       "      <th>gros</th>\n",
       "      <th>le</th>\n",
       "      <th>petit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chat  chien  gros  le  petit\n",
       "d1     1      0     0   1      1\n",
       "d2     0      2     1   1      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création naïve de la matrice X\n",
    "X = np.array([[1, 0, 0, 1, 1], [0, 2, 1, 1, 0]])\n",
    "X_df = pd.DataFrame(X, columns=['chat', 'chien', 'gros', 'le', 'petit'], index=['d1', 'd2'])\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1],\n",
       "       [0, 2, 1, 1, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices creuses\n",
    "Beaucoup de coordonnées sont nulles dans notre matrice (car beaucoup de mots du vocabulaire sont absents d'un document donné), pour optimiser la manipulation on va utiliser l'implémentation des matrices creuses par la bibiothèque Scipy: sparse matrix  \n",
    "Conversion des sacs de mots des documents en une matrice creuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dok_matrix((len(documents), len(V)), dtype=np.int)\n",
    "\n",
    "# Alimentation de la matrice creuse à partir des décomptes dans les sacs de mots\n",
    "for idx, document in enumerate(documents):\n",
    "    for word, count in document.items():\n",
    "        X[idx, V.index(word)] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 1, 1],\n",
       "        [0, 2, 1, 1, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application à notre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation de la liste de critiques en liste de sacs de mots\n",
    "# Transformation du vocabulaire en liste ordonnée des mots pour les coordonnées\n",
    "# Dictionnaire qui a un mot associe son index dans vocabulary {word: index}\n",
    "# Alimentation de la matrice creuse à partir des décomptes dans les sacs de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation de nos données d'entraînement à scikit learn `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création et entraînement d'un classificateur MultinomialNB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation en faisant des prédictions sur l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation sur l'ensemble de test\n",
    "\n",
    "### `X_test`\n",
    "Création d'une matrice creuse à partir des décomptes dans les sacs de mots de `test`\n",
    "\n",
    "On suit les mêmes étapes pour le traitement des critiques `reviews` de `test`  \n",
    "- preprocess\n",
    "- tokenize\n",
    "- bow\n",
    "\n",
    "Lors de l'alimentation de la matrice creuse, on ignore tous les mots que l'on n'a pas vu dans l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métriques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
